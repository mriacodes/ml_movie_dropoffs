{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1923780-20db-4dd8-a9a8-fd2b2cb87b33",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e011ef9f-10d0-419b-8c9b-9deae4028d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the IMDB dataset\n",
    "df = pd.read_csv('imdb_data.csv')\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e89d20-ed5d-4051-b606-b29f392c9849",
   "metadata": {},
   "source": [
    "## Step 2: Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fbd876-37f8-43fc-981f-1f33ecff706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info\n",
    "print(\"=== DATASET INFO ===\")\n",
    "print(df.info())\n",
    "print(\"\\n=== FIRST 5 ROWS ===\")\n",
    "print(df.head())\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n=== DUPLICATE ROWS ===\")\n",
    "print(f\"Total duplicate rows: {df.duplicated().sum()}\")\n",
    "print(\"\\n=== DUPLICATE MOVIE TITLES ===\")\n",
    "print(f\"Duplicate movie titles: {df.duplicated(subset=['movie_title']).sum()}\")\n",
    "print(\"\\n=== BASIC STATISTICS ===\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8725395-0b57-48c9-96d0-16a8429b455d",
   "metadata": {},
   "source": [
    "## Step 3: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95754037-1244-46cb-afde-b8b3fbd1c135",
   "metadata": {},
   "source": [
    "#### Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf18ea8-c15a-481a-96c2-fe9950622024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the percentage of missing values for each column\n",
    "print(\"=== MISSING VALUES PERCENTAGE ===\")\n",
    "missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "print(missing_percent.sort_values(ascending=False))\n",
    "\n",
    "# Handle missing values based on column type and importance\n",
    "print(\"\\n=== HANDLING MISSING VALUES ===\")\n",
    "\n",
    "# For numerical columns - fill with median\n",
    "numerical_cols = ['imdb_score', 'title_year', 'duration']\n",
    "for col in numerical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        median_val = df[col].median()\n",
    "        df[col] = df[col].fillna(median_val)\n",
    "        print(f\"Filled {col} missing values with median: {median_val}\")\n",
    "\n",
    "# For categorical columns - fill with mode or 'Unknown'\n",
    "categorical_cols = ['content_rating', 'main_genre', 'director_name', 'star_cast']\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        if col in ['content_rating', 'main_genre']:\n",
    "            mode_val = df[col].mode()[0] if not df[col].mode().empty else 'Unknown'\n",
    "            df[col] = df[col].fillna(mode_val)\n",
    "            print(f\"Filled {col} missing values with mode: {mode_val}\")\n",
    "        else:\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "            print(f\"Filled {col} missing values with 'Unknown'\")\n",
    "\n",
    "# For movie_title - drop rows with missing titles (essential field)\n",
    "if df['movie_title'].isnull().sum() > 0:\n",
    "    initial_count = len(df)\n",
    "    df = df.dropna(subset=['movie_title'])\n",
    "    print(f\"Dropped {initial_count - len(df)} rows with missing movie titles\")\n",
    "\n",
    "print(f\"\\nMissing values after cleaning: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e441237-f839-40e4-8f0a-00dc5d196282",
   "metadata": {},
   "source": [
    "#### Clean Specific Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061bab84-67d5-4c9b-bb8c-b6ec48aeb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean movie_title column (remove trailing spaces and special characters)\n",
    "print(\"=== CLEANING MOVIE TITLES ===\")\n",
    "df['movie_title'] = df['movie_title'].str.strip()\n",
    "# Remove special characters that might cause issues but keep the actual title readable\n",
    "df['movie_title'] = df['movie_title'].str.replace(r'[^\\w\\s\\-\\:\\.\\,\\!\\?\\(\\)]', '', regex=True)\n",
    "print(f\"Cleaned movie titles\")\n",
    "\n",
    "# Clean and standardize content_rating\n",
    "print(\"\\n=== CLEANING CONTENT RATING ===\")\n",
    "print(\"Original content ratings:\")\n",
    "print(df['content_rating'].value_counts())\n",
    "# Standardize content ratings\n",
    "df['content_rating'] = df['content_rating'].str.upper().str.strip()\n",
    "print(\"\\nStandardized content ratings:\")\n",
    "print(df['content_rating'].value_counts())\n",
    "\n",
    "# Clean director_name and star_cast\n",
    "print(\"\\n=== CLEANING DIRECTOR AND CAST ===\")\n",
    "df['director_name'] = df['director_name'].str.strip()\n",
    "df['star_cast'] = df['star_cast'].str.strip()\n",
    "\n",
    "# Clean genres column - we'll separate this into individual genre columns later\n",
    "print(\"\\n=== CLEANING GENRES ===\")\n",
    "df['genres'] = df['genres'].str.strip()\n",
    "print(f\"Sample genres: {df['genres'].head()}\")\n",
    "\n",
    "print(\"\\nColumn cleaning completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7fb1f7-e1e9-4fe2-8bd3-96ea9f799df4",
   "metadata": {},
   "source": [
    "#### Handle Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66372a5-89eb-4ea8-b863-d67cb75501a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate movie titles\n",
    "print(\"=== HANDLING DUPLICATES ===\")\n",
    "print(f\"Total rows before duplicate removal: {len(df)}\")\n",
    "print(f\"Duplicate movie titles: {df.duplicated(subset=['movie_title']).sum()}\")\n",
    "\n",
    "# Show some examples of duplicate titles\n",
    "duplicates = df[df.duplicated(subset=['movie_title'], keep=False)].sort_values('movie_title')\n",
    "if len(duplicates) > 0:\n",
    "    print(\"\\nSample duplicate titles:\")\n",
    "    print(duplicates[['movie_title', 'title_year', 'imdb_score']].head(10))\n",
    "\n",
    "# Drop duplicates keeping the first occurrence\n",
    "df = df.drop_duplicates(subset=['movie_title'], keep='first')\n",
    "print(f\"\\nRows after duplicate removal: {len(df)}\")\n",
    "print(f\"Removed {len(duplicates) - len(df[df.duplicated(subset=['movie_title'], keep=False)])} duplicate rows\")\n",
    "\n",
    "# Check for complete duplicate rows\n",
    "complete_duplicates = df.duplicated().sum()\n",
    "if complete_duplicates > 0:\n",
    "    print(f\"\\nComplete duplicate rows found: {complete_duplicates}\")\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"Rows after removing complete duplicates: {len(df)}\")\n",
    "else:\n",
    "    print(\"\\nNo complete duplicate rows found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6783c877-5857-4eda-931f-e8b55d5e407b",
   "metadata": {},
   "source": [
    "#### Convert Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e104fd-060b-40ee-bb18-5da15a189849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types appropriately\n",
    "print(\"=== CONVERTING DATA TYPES ===\")\n",
    "\n",
    "# Ensure imdb_score is numeric\n",
    "df['imdb_score'] = pd.to_numeric(df['imdb_score'], errors='coerce')\n",
    "print(f\"imdb_score converted to numeric, null values: {df['imdb_score'].isnull().sum()}\")\n",
    "\n",
    "# Ensure title_year is integer\n",
    "df['title_year'] = pd.to_numeric(df['title_year'], errors='coerce').astype('Int64')\n",
    "print(f\"title_year converted to integer, null values: {df['title_year'].isnull().sum()}\")\n",
    "\n",
    "# Ensure duration is numeric\n",
    "df['duration'] = pd.to_numeric(df['duration'], errors='coerce')\n",
    "print(f\"duration converted to numeric, null values: {df['duration'].isnull().sum()}\")\n",
    "\n",
    "# Check data types after conversion\n",
    "print(\"\\n=== DATA TYPES AFTER CONVERSION ===\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for any remaining null values created during conversion\n",
    "print(\"\\n=== NULL VALUES AFTER TYPE CONVERSION ===\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill any new null values created during conversion\n",
    "if df['imdb_score'].isnull().sum() > 0:\n",
    "    df['imdb_score'] = df['imdb_score'].fillna(df['imdb_score'].median())\n",
    "if df['title_year'].isnull().sum() > 0:\n",
    "    df['title_year'] = df['title_year'].fillna(df['title_year'].median())\n",
    "if df['duration'].isnull().sum() > 0:\n",
    "    df['duration'] = df['duration'].fillna(df['duration'].median())\n",
    "\n",
    "print(\"Data type conversion completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095dd43c-ed4b-40dd-928f-06b0bf78d923",
   "metadata": {},
   "source": [
    "#### Create New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098351be-b7a5-429d-8900-49bb4b9aebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features for better analysis\n",
    "print(\"=== CREATING NEW FEATURES ===\")\n",
    "\n",
    "# Separate genres into individual columns\n",
    "print(\"\\nSeparating genres into individual columns...\")\n",
    "# Split genres by comma and strip whitespace\n",
    "genre_split = df['genres'].str.split(',').apply(lambda x: [genre.strip() for genre in x] if x else [])\n",
    "\n",
    "# Find the maximum number of genres any movie has\n",
    "max_genres = max(len(genres) for genres in genre_split)\n",
    "print(f\"Maximum number of genres for any movie: {max_genres}\")\n",
    "\n",
    "# Create individual genre columns\n",
    "for i in range(max_genres):\n",
    "    col_name = f\"genre_{i+1}\"\n",
    "    df[col_name] = genre_split.apply(lambda x: x[i] if i < len(x) else None)\n",
    "    print(f\"Created {col_name}\")\n",
    "\n",
    "# Create a genre count feature\n",
    "df['genre_count'] = genre_split.apply(len)\n",
    "print(f\"Created genre_count feature\")\n",
    "\n",
    "# Create decade feature from title_year\n",
    "df['decade'] = (df['title_year'] // 10) * 10\n",
    "print(f\"Created decade feature\")\n",
    "\n",
    "# Create IMDB score categories\n",
    "df['imdb_category'] = pd.cut(df['imdb_score'], \n",
    "                           bins=[0, 5, 7, 8, 10], \n",
    "                           labels=['Poor', 'Average', 'Good', 'Excellent'])\n",
    "print(f\"Created imdb_category feature\")\n",
    "\n",
    "# Create duration categories\n",
    "df['duration_category'] = pd.cut(df['duration'],\n",
    "                                bins=[0, 90, 120, 180, float('inf')],\n",
    "                                labels=['Short', 'Medium', 'Long', 'Very Long'])\n",
    "print(f\"Created duration_category feature\")\n",
    "\n",
    "# Show the first few rows with new features\n",
    "print(\"\\n=== SAMPLE OF NEW FEATURES ===\")\n",
    "new_feature_cols = ['genre_1', 'genre_2', 'genre_3', 'genre_count', 'decade', 'imdb_category', 'duration_category']\n",
    "print(df[['movie_title'] + new_feature_cols].head())\n",
    "\n",
    "# Show genre distribution\n",
    "print(\"\\n=== GENRE DISTRIBUTION ===\")\n",
    "print(\"Top 10 first genres:\")\n",
    "print(df['genre_1'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nFeature creation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db994ddd-529f-4802-93c9-89a9dc6fc3e6",
   "metadata": {},
   "source": [
    "## Step 4: Outlier Detection and Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cdd30-dd3f-4617-a6bc-c5904eb3a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize numerical columns for outliers\n",
    "print(\"=== OUTLIER DETECTION AND HANDLING ===\")\n",
    "\n",
    "# Check the distribution of numerical columns\n",
    "numerical_cols = ['imdb_score', 'title_year', 'duration']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    df[col].hist(ax=axes[i], bins=30, alpha=0.7)\n",
    "    axes[i].set_title(f'Distribution of {col}')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create boxplots to visualize outliers\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    df.boxplot(column=col, ax=axes[i])\n",
    "    axes[i].set_title(f'Boxplot of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify outliers using IQR method\n",
    "print(\"\\n=== OUTLIER STATISTICS ===\")\n",
    "outlier_info = {}\n",
    "for col in numerical_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    outlier_info[col] = {\n",
    "        'count': len(outliers),\n",
    "        'percentage': (len(outliers) / len(df)) * 100,\n",
    "        'lower_bound': lower_bound,\n",
    "        'upper_bound': upper_bound\n",
    "    }\n",
    "    \n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  Outliers: {len(outliers)} ({(len(outliers)/len(df)*100):.2f}%)\")\n",
    "    print(f\"  Lower bound: {lower_bound:.2f}\")\n",
    "    print(f\"  Upper bound: {upper_bound:.2f}\")\n",
    "    print(f\"  Min value: {df[col].min():.2f}\")\n",
    "    print(f\"  Max value: {df[col].max():.2f}\")\n",
    "    print()\n",
    "\n",
    "# Handle outliers for duration only (as IMDB score and year shouldn't be capped)\n",
    "print(\"=== HANDLING OUTLIERS ===\")\n",
    "duration_outliers_before = len(df[(df['duration'] < outlier_info['duration']['lower_bound']) | \n",
    "                                 (df['duration'] > outlier_info['duration']['upper_bound'])])\n",
    "\n",
    "# Cap duration outliers\n",
    "df['duration'] = np.where(df['duration'] < outlier_info['duration']['lower_bound'], \n",
    "                         outlier_info['duration']['lower_bound'], df['duration'])\n",
    "df['duration'] = np.where(df['duration'] > outlier_info['duration']['upper_bound'], \n",
    "                         outlier_info['duration']['upper_bound'], df['duration'])\n",
    "\n",
    "print(f\"Capped {duration_outliers_before} duration outliers\")\n",
    "print(\"Note: IMDB score and year outliers were kept as they represent valid extreme values\")\n",
    "\n",
    "print(\"\\nOutlier handling completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d679c-0271-42d6-9443-06f6135ab01d",
   "metadata": {},
   "source": [
    "## Step 5: Final Checks and Save Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04305f3b-4786-40b5-b86c-f719d7173018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final data quality checks and summary\n",
    "print(\"=== FINAL DATA QUALITY CHECKS ===\")\n",
    "\n",
    "# Check cleaned data info\n",
    "print(\"Dataset info after cleaning:\")\n",
    "print(df.info())\n",
    "\n",
    "# Check for any remaining missing values\n",
    "print(f\"\\nMissing values after cleaning: {df.isnull().sum().sum()}\")\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    print(\"Missing values by column:\")\n",
    "    print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n=== SUMMARY STATISTICS ===\")\n",
    "print(df.describe())\n",
    "\n",
    "# Show sample of cleaned data\n",
    "print(\"\\n=== SAMPLE OF CLEANED DATA ===\")\n",
    "print(df.head())\n",
    "\n",
    "# Data quality metrics\n",
    "print(\"\\n=== DATA QUALITY METRICS ===\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Movies per decade:\")\n",
    "print(df['decade'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nContent rating distribution:\")\n",
    "print(df['content_rating'].value_counts())\n",
    "\n",
    "print(f\"\\nTop 10 genres:\")\n",
    "print(df['genre_1'].value_counts().head(10))\n",
    "\n",
    "print(f\"\\nIMDB score distribution:\")\n",
    "print(df['imdb_category'].value_counts())\n",
    "\n",
    "# Save cleaned data\n",
    "output_filename = 'cleaned_imdb_data.csv'\n",
    "df.to_csv(output_filename, index=False)\n",
    "print(f\"\\n=== DATA SAVED ===\")\n",
    "print(f\"Cleaned data saved to: {output_filename}\")\n",
    "print(f\"Shape of saved data: {df.shape}\")\n",
    "\n",
    "# Show final column list\n",
    "print(f\"\\nFinal columns in cleaned dataset:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(\"\\n✅ Data cleaning completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7451a26-d903-46e0-9807-69a6f2718a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final dataset structure and data dictionary\n",
    "print(\"=== FINAL DATASET STRUCTURE ===\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n=== DATA DICTIONARY ===\")\n",
    "data_dict = {\n",
    "    'movie_title': 'Movie title (cleaned)',\n",
    "    'imdb_score': 'IMDB rating score (0-10)',\n",
    "    'title_year': 'Year the movie was released',\n",
    "    'content_rating': 'Content rating (G, PG, PG-13, R, etc.)',\n",
    "    'main_genre': 'Primary genre of the movie',\n",
    "    'director_name': 'Director name',\n",
    "    'star_cast': 'Main cast members',\n",
    "    'genres': 'Original genres string (comma-separated)',\n",
    "    'duration': 'Movie duration in minutes',\n",
    "    'genre_1': 'First genre',\n",
    "    'genre_2': 'Second genre (if applicable)',\n",
    "    'genre_3': 'Third genre (if applicable)',\n",
    "    'genre_count': 'Number of genres assigned to the movie',\n",
    "    'decade': 'Decade the movie was released',\n",
    "    'imdb_category': 'IMDB score category (Poor/Average/Good/Excellent)',\n",
    "    'duration_category': 'Duration category (Short/Medium/Long/Very Long)'\n",
    "}\n",
    "\n",
    "for col in df.columns:\n",
    "    if col in data_dict:\n",
    "        print(f\"{col:18} - {data_dict[col]}\")\n",
    "    else:\n",
    "        # For dynamically created genre columns\n",
    "        if col.startswith('genre_') and col != 'genre_count':\n",
    "            print(f\"{col:18} - {col.replace('_', ' ').title()}\")\n",
    "\n",
    "print(\"\\n=== READY FOR NEXT STEPS ===\")\n",
    "print(\"✅ Data preprocessing completed\")\n",
    "print(\"✅ Duplicates removed\")\n",
    "print(\"✅ Missing values handled\")\n",
    "print(\"✅ Genres separated into individual columns\")\n",
    "print(\"✅ New features created\")\n",
    "print(\"✅ Outliers handled\")\n",
    "print(\"✅ Data types standardized\")\n",
    "print(\"\\nThe cleaned dataset is now ready for feature engineering and modeling!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
